{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Er81N23oNVqK",
        "outputId": "59a935a1-0c9d-4a84-885b-110260f7f8d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqX54YzBNd5f",
        "outputId": "d65d610b-5577-4d4d-a582-e5a1f946a7b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-t9hnolcl\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-t9hnolcl\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 781ff5b76ba6c4c2d80dcbbec9983e147613cc71\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.1.0-py3-none-any.whl size=8011 sha256=e2b2acbb79d726227ace2ffdeb18b901e4debb9cf9419b13a35a389a655ee4ac\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0sgs275b/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0a_SttTNd9Z",
        "outputId": "bb524af2-d081-4a50-e188-5a7e157a4960"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source files will be saved in \"/tmp/tmpgyazkicd\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question1 (Q1)**"
      ],
      "metadata": {
        "id": "PyuCMKED0dgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%writefile Q1_2_31_2_33.cu\n",
        "//Norhan_Reda_Abdelwahed_2_31\n",
        "//Hoda_Gamal_Hamouda_2_33\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <assert.h>\n",
        "#include <iostream>\n",
        "#include <fstream>\n",
        "#include <vector>\n",
        "using namespace std;\n",
        "\n",
        "// Kernel definition\n",
        "__global__ void ArrAdd(float *arr, int size,float *result)\n",
        "{\n",
        "    // declares a shared memory segment that is accessible by all threads in the same block. More on this later.\n",
        "extern __shared__ float partialSum[];\n",
        "\n",
        "unsigned int thread_id = blockIdx.x * blockDim.x + threadIdx.x ;\n",
        "\n",
        "unsigned int t = threadIdx.x;\n",
        "\n",
        "partialSum[t] = arr[thread_id];\n",
        "\n",
        "if(thread_id >=size)\n",
        "   return ;\n",
        "for(unsigned int stride = 1; stride < blockDim.x; stride *= 2){\n",
        "\n",
        "     if(t % (2*stride) == 0)\n",
        "          partialSum[t] += partialSum[t+stride];\n",
        "     __syncthreads();\n",
        "}\n",
        "\n",
        " if(t==0)\n",
        "     *result = partialSum[0];\n",
        "\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[])\n",
        "{\n",
        "\n",
        "\n",
        "    // Specify the file path\n",
        "    std::string filePath = argv[1];\n",
        "\n",
        "    // Open the file for reading\n",
        "    std::ifstream file(filePath);\n",
        "\n",
        "   if (!file.is_open()) {\n",
        "        std::cerr << \"Error opening file\" << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        " float* array = nullptr;  // Pointer to the array\n",
        " float * result = nullptr;\n",
        "    float value;\n",
        "    int count = 0;  // Variable to keep track of the number of elements\n",
        "\n",
        "    // Read elements from the file\n",
        "    while (file >> value) {\n",
        "        // Dynamically resize the array\n",
        "        float* temp = static_cast<float*>(realloc(array, (count + 1) * sizeof(float)));\n",
        "\n",
        "        if (temp == nullptr) {\n",
        "            std::cerr << \"Error allocating memory\" << std::endl;\n",
        "            free(array);  // Free the previously allocated memory\n",
        "            return 1;\n",
        "        }\n",
        "\n",
        "        array = temp;\n",
        "\n",
        "        // Add the read value to the array\n",
        "        array[count] = value;\n",
        "\n",
        "        count++;\n",
        "    }\n",
        "\n",
        "    // Close the file\n",
        "    file.close();\n",
        "\n",
        "    // Print the elements in the array\n",
        "    for (int i = 0; i < count; i++) {\n",
        "        std::cout << array[i] << std::endl;\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "    // host to device allocation\n",
        "     float *array_device;\n",
        "     float *result_device;\n",
        "\n",
        "     result = (float*)malloc(sizeof(float));\n",
        "     cudaMalloc((void**)&array_device, count * sizeof(float));\n",
        "     cudaMalloc((void**)&result_device,sizeof(float));\n",
        "\n",
        "    cudaMemcpy(array_device, array, count * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    dim3 threadsPerBlock(256, 1);\n",
        "    dim3 numBlocks(1,1);\n",
        "    ArrAdd<<< numBlocks, threadsPerBlock , threadsPerBlock.x * sizeof(float) >>>(array_device,count,result_device);\n",
        "\n",
        "    cudaMemcpy( result, result_device, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cout<<\"final sum is: \"<<*result<<endl;\n",
        "\n",
        "\n",
        "    // Free the dynamically allocated memory in host\n",
        "    free(array);\n",
        "    free(result);\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(array_device);\n",
        "    cudaFree(array);\n",
        "\n",
        "   return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXPYfwzvNd_l",
        "outputId": "6113601a-2107-419e-e2ca-9d5fab5c8912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Q1_2_31_2_33.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x Q1_2_31_2_33.cu\n",
        "!nvcc Q1_2_31_2_33.cu -o Q1\n",
        "!./Q1 \"input.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1MPjpioNeBk",
        "outputId": "eb577bc3-10b8-4103-9cf6-9414eb40f6a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2\n",
            "3.8\n",
            "6.4\n",
            "7.9\n",
            "final sum is: 19.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ulsm9FHU0Rfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question2 (Q2)**"
      ],
      "metadata": {
        "id": "pPvtdQBB0Ul2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%writefile Q2_2_31_2_33.cu\n",
        "//Norhan_Reda_Abdelwahed_2_31\n",
        "//Hoda_Gamal_Hamouda_2_33\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <assert.h>\n",
        "#include <iostream>\n",
        "#include <fstream>\n",
        "#include <vector>\n",
        "\n",
        "#define BLOCKDIM 512\n",
        "#define SEARCH_CHUNK 16\n",
        "#define BLOCK_CHUNK (BLOCKDIM*SEARCH_CHUNK)\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// Kernel definition\n",
        "__global__ void BinarySearch(float *arr, int len,float search,float *res,bool* flag)\n",
        "{\n",
        "\n",
        "     if(*flag == false) {\n",
        "        int tid = threadIdx.x;\n",
        "        __shared__ float s_arr[BLOCK_CHUNK];\n",
        "\n",
        "        /* Since each value is being copied to shared memory, the rest of the\n",
        "        following uncommented code is unncessary, since a direct comparison\n",
        "        can be done at the time of copy below. */\n",
        "        // for(int i = 0; i < BLOCKDIM; ++i) {\n",
        "        //     int shared_loc = i*SEARCH_CHUNK + tid;\n",
        "        //     int global_loc = shared_loc + BLOCK_CHUNK * blockIdx.x;\n",
        "        //     if(arr[global_loc] == search) {\n",
        "        //         *flag = true;\n",
        "        //         *res = global_loc;\n",
        "        //     }\n",
        "        //     __syncthreads();\n",
        "        // }\n",
        "\n",
        "        /* Copy chunk of array that this entire block of threads will read\n",
        "        from the slower global memory to the faster shared memory. */\n",
        "        for(int i = 0; i < SEARCH_CHUNK; ++i) {\n",
        "            int shared_loc = tid*SEARCH_CHUNK + i;\n",
        "            int global_loc = shared_loc + BLOCK_CHUNK * blockIdx.x;\n",
        "\n",
        "            /* Make sure to stay within the bounds of the global array,\n",
        "            else assign a dummy value. */\n",
        "            if(global_loc < len) {\n",
        "              s_arr[shared_loc] = arr[global_loc];\n",
        "            }\n",
        "            else {\n",
        "              s_arr[shared_loc] = INT_MAX;\n",
        "            }\n",
        "        }\n",
        "        __syncthreads();\n",
        "\n",
        "        /* For each thread, set the initial search range. */\n",
        "        int L = 0;\n",
        "        int R = SEARCH_CHUNK - 1;\n",
        "        int m = (L + R) / 2;\n",
        "\n",
        "        /* Pointer to the part of the shared array for this thread. */\n",
        "        float *s_ptr = &s_arr[tid*SEARCH_CHUNK];\n",
        "\n",
        "        /* Each thread will search a chunk of the block array.\n",
        "        Many blocks will not find a solution so the search must\n",
        "        be allowed to fail on a per block basis. The loop will\n",
        "        break (fail) when L >= R. */\n",
        "\n",
        "        while(L <= R && *flag == false)\n",
        "        {\n",
        "            if(s_ptr[m] < search) {\n",
        "                L = m + 1;\n",
        "            }\n",
        "            else if(s_ptr[m] > search) {\n",
        "                R = m - 1;\n",
        "            }\n",
        "            else {\n",
        "                *flag = true;\n",
        "                *res = m + tid*SEARCH_CHUNK + BLOCK_CHUNK * blockIdx.x;\n",
        "            }\n",
        "\n",
        "            m = (L + R) / 2;\n",
        "        }\n",
        "        if (*flag == false){\n",
        "          *res = -1;\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main(int argc, char *argv[])\n",
        "{\n",
        "\n",
        "\n",
        "    // Specify the file path\n",
        "    std::string filePath = argv[1];\n",
        "    float target = atof(argv[2]);\n",
        "    // Open the file for reading\n",
        "    std::ifstream file(filePath);\n",
        "\n",
        "   if (!file.is_open()) {\n",
        "        std::cerr << \"Error opening file\" << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        " float* array = nullptr;  // Pointer to the array\n",
        " float * result = nullptr;\n",
        "    float value;\n",
        "    int count = 0;  // Variable to keep track of the number of elements\n",
        "\n",
        "    // Read elements from the file\n",
        "    while (file >> value) {\n",
        "        // Dynamically resize the array\n",
        "        float* temp = static_cast<float*>(realloc(array, (count + 1) * sizeof(float)));\n",
        "\n",
        "        if (temp == nullptr) {\n",
        "            std::cerr << \"Error allocating memory\" << std::endl;\n",
        "            free(array);  // Free the previously allocated memory\n",
        "            return 1;\n",
        "        }\n",
        "\n",
        "        array = temp;\n",
        "\n",
        "        // Add the read value to the array\n",
        "        array[count] = value;\n",
        "\n",
        "        count++;\n",
        "    }\n",
        "\n",
        "    // Close the file\n",
        "    file.close();\n",
        "\n",
        "    // Print the elements in the array\n",
        "    for (int i = 0; i < count; i++) {\n",
        "        std::cout << array[i] << std::endl;\n",
        "    }\n",
        "\n",
        "\n",
        "      bool * flag;\n",
        "    // host to device allocation\n",
        "     float *array_device;\n",
        "     float *result_device;\n",
        "      bool * flag_device;\n",
        "\n",
        "     result = (float*)malloc(sizeof(float));\n",
        "     flag = (bool*)malloc(sizeof(bool));\n",
        "     *flag = false;\n",
        "\n",
        "     cudaMalloc((void**)&array_device, count * sizeof(float));\n",
        "     cudaMalloc((void**)&result_device,sizeof(float));\n",
        "     cudaMalloc((void**)&flag_device,sizeof(bool));\n",
        "\n",
        "    cudaMemcpy(array_device, array, count * sizeof(float), cudaMemcpyHostToDevice);\n",
        "        cudaMemcpy(flag_device, flag, sizeof(bool), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 threadsPerBlock(512, 1);\n",
        "    dim3 numBlocks(1,1);\n",
        "    BinarySearch<<< numBlocks, threadsPerBlock , threadsPerBlock.x * sizeof(float) >>>(array_device,count, target,result_device,flag_device);\n",
        "\n",
        "    cudaMemcpy( result, result_device, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cout<<\"target index : \"<<*result<<endl;\n",
        "\n",
        "\n",
        "    // Free the dynamically allocated memory in host\n",
        "    free(array);\n",
        "    free(result);\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(array_device);\n",
        "    cudaFree(array);\n",
        "\n",
        "   return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJyRwghBNeDp",
        "outputId": "19805fc8-24a8-45ba-9697-46b0e753af76"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Q2_2_31_2_33.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x Q2_2_31_2_33.cu\n",
        "!nvcc Q2_2_31_2_33.cu -o Q2\n",
        "!./Q2 \"input.txt\" 1.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIKLz3oCNeFn",
        "outputId": "f25b59fd-4f8c-403a-da4a-827a6a81f1f6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2\n",
            "3.8\n",
            "6.4\n",
            "7.9\n",
            "target index : -1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./Q2 \"input.txt\" 3.8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0OP5yVwH_OX",
        "outputId": "76ce1477-b64b-45ab-bbee-6c44c21e6d5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2\n",
            "3.8\n",
            "6.4\n",
            "7.9\n",
            "==10318== NVPROF is profiling process 10318, command: ./Q2 input.txt 3.8\n",
            "target index : 1\n",
            "==10318== Profiling application: ./Q2 input.txt 3.8\n",
            "==10318== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   78.04%  13.984us         1  13.984us  13.984us  13.984us  BinarySearch(float*, int, float, float*, bool*)\n",
            "                   11.61%  2.0800us         1  2.0800us  2.0800us  2.0800us  [CUDA memcpy DtoH]\n",
            "                   10.36%  1.8560us         2     928ns     704ns  1.1520us  [CUDA memcpy HtoD]\n",
            "      API calls:   99.64%  187.07ms         3  62.358ms  3.3460us  187.06ms  cudaMalloc\n",
            "                    0.24%  443.11us         1  443.11us  443.11us  443.11us  cudaLaunchKernel\n",
            "                    0.07%  132.36us       114  1.1610us     139ns  49.385us  cuDeviceGetAttribute\n",
            "                    0.03%  55.657us         3  18.552us  6.7800us  27.157us  cudaMemcpy\n",
            "                    0.01%  23.295us         2  11.647us  3.6650us  19.630us  cudaFree\n",
            "                    0.01%  11.740us         1  11.740us  11.740us  11.740us  cuDeviceGetName\n",
            "                    0.00%  5.3900us         1  5.3900us  5.3900us  5.3900us  cuDeviceGetPCIBusId\n",
            "                    0.00%  4.3330us         1  4.3330us  4.3330us  4.3330us  cuDeviceTotalMem\n",
            "                    0.00%  1.9070us         3     635ns     250ns  1.3920us  cuDeviceGetCount\n",
            "                    0.00%  1.2180us         2     609ns     172ns  1.0460us  cuDeviceGet\n",
            "                    0.00%     761ns         1     761ns     761ns     761ns  cuModuleGetLoadingMode\n",
            "                    0.00%     205ns         1     205ns     205ns     205ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%writefile Q2_2_31_2_33.cu\n",
        "//Norhan_Reda_Abdelwahed_2_31\n",
        "//Hoda_Gamal_Hamouda_2_33\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <assert.h>\n",
        "#include <iostream>\n",
        "#include <fstream>\n",
        "#include <vector>\n",
        "using namespace std;\n",
        "\n",
        "// Kernel definition\n",
        "__global__ void BinarySearch(float *array, int size,float target,float *result,bool* flag)\n",
        "{\n",
        "   if(*flag == false)\n",
        "   {\n",
        "       int tid = threadIdx.x;\n",
        "      __shared__ int s_arr[512*16];\n",
        "\n",
        "      for(int i = 0; i < 16; ++i) {\n",
        "            int shared_loc = tid*16 + i;\n",
        "            //int global_loc = shared_loc + 512*16 * blockIdx.x;\n",
        "            int global_loc = shared_loc;\n",
        "            /* Make sure to stay within the bounds of the global array,\n",
        "            else assign a dummy value. */\n",
        "            if(global_loc < size) {\n",
        "              s_arr[shared_loc] = array[global_loc];\n",
        "            }\n",
        "            else {\n",
        "              s_arr[shared_loc] = INT_MAX;\n",
        "            }\n",
        "        }\n",
        "        __syncthreads();\n",
        "\n",
        "        /* For each thread, set the initial search range. */\n",
        "        int L = 0;\n",
        "        int R = 16 - 1;\n",
        "        int m = (L + R) / 2;\n",
        "\n",
        "        /* Pointer to the part of the shared array for this thread. */\n",
        "        int *s_ptr = &s_arr[tid*16];\n",
        "\n",
        "        /* Each thread will search a chunk of the block array.\n",
        "        Many blocks will not find a solution so the search must\n",
        "        be allowed to fail on a per block basis. The loop will\n",
        "        break (fail) when L >= R. */\n",
        "        while(L <= R && *flag == false)\n",
        "        {\n",
        "            if(s_ptr[m] < target) {\n",
        "                L = m + 1;\n",
        "            }\n",
        "            else if(s_ptr[m] > target) {\n",
        "                R = m - 1;\n",
        "            }\n",
        "            else {\n",
        "                *flag = true;\n",
        "                *result = m + tid*16 + 512*16 * blockIdx.x;\n",
        "            }\n",
        "\n",
        "            m = (L + R) / 2;\n",
        "        }\n",
        "\n",
        "   }\n",
        "\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main(int argc, char *argv[])\n",
        "{\n",
        "\n",
        "\n",
        "    // Specify the file path\n",
        "    std::string filePath = argv[1];\n",
        "    float target = atof(argv[2]);\n",
        "    // Open the file for reading\n",
        "    std::ifstream file(filePath);\n",
        "\n",
        "   if (!file.is_open()) {\n",
        "        std::cerr << \"Error opening file\" << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        " float* array = nullptr;  // Pointer to the array\n",
        " float * result = nullptr;\n",
        "    float value;\n",
        "    int count = 0;  // Variable to keep track of the number of elements\n",
        "\n",
        "    // Read elements from the file\n",
        "    while (file >> value) {\n",
        "        // Dynamically resize the array\n",
        "        float* temp = static_cast<float*>(realloc(array, (count + 1) * sizeof(float)));\n",
        "\n",
        "        if (temp == nullptr) {\n",
        "            std::cerr << \"Error allocating memory\" << std::endl;\n",
        "            free(array);  // Free the previously allocated memory\n",
        "            return 1;\n",
        "        }\n",
        "\n",
        "        array = temp;\n",
        "\n",
        "        // Add the read value to the array\n",
        "        array[count] = value;\n",
        "\n",
        "        count++;\n",
        "    }\n",
        "\n",
        "    // Close the file\n",
        "    file.close();\n",
        "\n",
        "    // Print the elements in the array\n",
        "    for (int i = 0; i < count; i++) {\n",
        "        std::cout << array[i] << std::endl;\n",
        "    }\n",
        "\n",
        "\n",
        "      bool * flag;\n",
        "    // host to device allocation\n",
        "     float *array_device;\n",
        "     float *result_device;\n",
        "      bool * flag_device;\n",
        "\n",
        "     result = (float*)malloc(sizeof(float));\n",
        "     flag = (bool*)malloc(sizeof(bool));\n",
        "     *flag = false;\n",
        "\n",
        "     cudaMalloc((void**)&array_device, count * sizeof(float));\n",
        "     cudaMalloc((void**)&result_device,sizeof(float));\n",
        "     cudaMalloc((void**)&flag_device,sizeof(bool));\n",
        "\n",
        "    cudaMemcpy(array_device, array, count * sizeof(float), cudaMemcpyHostToDevice);\n",
        "        cudaMemcpy(flag_device, flag, sizeof(bool), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 threadsPerBlock(256, 1);\n",
        "    dim3 numBlocks(1,1);\n",
        "    BinarySearch<<< numBlocks, threadsPerBlock , threadsPerBlock.x * sizeof(float) >>>(array_device,count, target,result_device,flag_device);\n",
        "\n",
        "    cudaMemcpy( result, result_device, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cout<<\"target index : \"<<*result<<endl;\n",
        "\n",
        "\n",
        "    // Free the dynamically allocated memory in host\n",
        "    free(array);\n",
        "    free(result);\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(array_device);\n",
        "    cudaFree(array);\n",
        "\n",
        "   return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "8-TOWf1LtD3A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}