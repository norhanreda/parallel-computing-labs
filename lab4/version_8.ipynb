{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP5c-8VY9JUr",
        "outputId": "5d9a0cfa-f03c-4280-ef03-cd728ef226fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXV5nYXQ9Y6-",
        "outputId": "d101e89f-7863-4801-a0c8-f1d26edc1d4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-1j32ukh0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-1j32ukh0\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 5741c522547756ac4bb7a16df32106a15efb8a57\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6cpPyam9Y3m",
        "outputId": "61e85a97-d8a1-49ef-99fb-2be852034d5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The nvcc4jupyter extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc4jupyter\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWcubSkzHwlM",
        "outputId": "d87eb54d-a96d-4f43-9150-6c6a1ec19509"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'stb' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nothings/stb.git\n",
        "!cp stb/stb_image.h /usr/local/include/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9rqYPEurkE-",
        "outputId": "8bda988a-e921-4db7-dc2f-6aa31d6bd14f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n",
            "--2024-04-09 14:31:29--  https://raw.githubusercontent.com/nothings/stb/master/stb_image_write.h\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 71221 (70K) [text/plain]\n",
            "Saving to: ‘stb_image_write.h.1’\n",
            "\n",
            "stb_image_write.h.1 100%[===================>]  69.55K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-09 14:31:29 (16.5 MB/s) - ‘stb_image_write.h.1’ saved [71221/71221]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install wget\n",
        "!wget https://raw.githubusercontent.com/nothings/stb/master/stb_image_write.h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkLPMLRYpd6V"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtDTNaiMuQH4"
      },
      "source": [
        "# Final =========================>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cV7jPjXtxCD9",
        "outputId": "11bae447-1110-4b4e-b701-81da2884dfba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting K1_2_31_2_33.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile K1_2_31_2_33.cu\n",
        "//Norhan_Reda_Abdelwahed_2_31\n",
        "//Hoda_Gamal_Hamouda_2_33\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <assert.h>\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <fstream>\n",
        "#include <vector>\n",
        "#define STB_IMAGE_IMPLEMENTATION\n",
        "#include <stdio.h>\n",
        "#include \"stb_image.h\"\n",
        "#define STB_IMAGE_WRITE_IMPLEMENTATION\n",
        "#include \"stb_image_write.h\"\n",
        "#include <string>\n",
        "#include <filesystem>\n",
        "#include <cuda_runtime.h>\n",
        "using namespace std;\n",
        "\n",
        "// Kernel definition\n",
        "__global__ void Imgcov3d(int batchSize, float *input, float* output ,unsigned int width, unsigned int height , const float* __restrict__ mask, int maskdim){\n",
        "\n",
        "    int outRow = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int outCol = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int imageIndex = blockIdx.z * blockDim.z + threadIdx.z;\n",
        "\n",
        "    if(outRow < height && outCol < width && imageIndex < batchSize) {\n",
        "\n",
        "      float sum = 0;\n",
        "\n",
        "        for(int maskRow = 0; maskRow < maskdim; ++maskRow){\n",
        "           for(int maskCol = 0; maskCol < maskdim; ++maskCol){\n",
        "              for(int maskdep = 0; maskdep < 3; ++maskdep){\n",
        "\n",
        "                  int inRow = outRow -(maskdim/2) + maskRow;\n",
        "                  int inCol = outCol -(maskdim/2) + maskCol;\n",
        "\n",
        "                  if(inRow < height && inRow >= 0 && inCol < width && inCol >= 0){\n",
        "                      sum += mask[maskdep * maskdim * maskdim + maskRow * maskdim + maskCol]\n",
        "                      *input[imageIndex * width * height * 3 + maskdep * width * height + inRow * width + inCol];\n",
        "                  }\n",
        "             }\n",
        "          }\n",
        "        }\n",
        "        if(sum < 0){\n",
        "          sum = 0;\n",
        "        } else if (sum > 255){\n",
        "          sum = 255;\n",
        "        }\n",
        "        output[imageIndex * width * height + outRow * width + outCol] = sum;\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[]) {\n",
        "\n",
        "    string folderPath = argv[1];\n",
        "    string out_path = argv[2];\n",
        "    int batch_size = stoi(argv[3]);\n",
        "    string mask_path = argv[4];\n",
        "\n",
        "    int maskdim;\n",
        "\n",
        "    // Open the file for reading\n",
        "    std::ifstream inputFile(mask_path);\n",
        "\n",
        "    // Check if the file is opened successfully\n",
        "    if (!inputFile.is_open()) {\n",
        "        std::cerr << \"Error opening file: \" <<mask_path  << std::endl;\n",
        "        return 1; // Exit with an error code\n",
        "    }\n",
        "\n",
        "     inputFile >> maskdim ;\n",
        "     cout<<\"maskdim \"<<maskdim<<endl;\n",
        "\n",
        "    float *h_A, *h_B,*R,*G,*B;\n",
        "    int rows1,cols1, comp;\n",
        "\n",
        "    float *h_images;\n",
        "    int img_index = 0;\n",
        "\n",
        "    for (const auto& entry : std::filesystem::directory_iterator(folderPath)) {\n",
        "\n",
        "        if (entry.is_regular_file()) {\n",
        "            std::string filePath = entry.path().string();\n",
        "\n",
        "            unsigned char *data = stbi_load(filePath.c_str(), &cols1, &rows1, &comp, 0);\n",
        "\n",
        "            if(img_index == 0){\n",
        "              h_images = (float*)malloc(sizeof(float) * batch_size * cols1 * rows1 * comp);\n",
        "            }\n",
        "\n",
        "            if (data) {\n",
        "\n",
        "                printf(\"cols %d\\n\", cols1);\n",
        "                printf(\"rows %d\\n\", rows1);\n",
        "                printf(\"image %s\\n\", filePath.c_str());\n",
        "\n",
        "                h_A = (float*)malloc(sizeof(float) *  rows1 * cols1* comp);\n",
        "                R = (float*)malloc(sizeof(float) *  rows1 * cols1);\n",
        "                G = (float*)malloc(sizeof(float) *  rows1 * cols1);\n",
        "                B = (float*)malloc(sizeof(float) *  rows1 * cols1);\n",
        "\n",
        "                int k = 0;\n",
        "                for(int i=0;i<rows1 * cols1* comp;i=i+3)\n",
        "                {\n",
        "                  R[k] =  static_cast<float>(data[i]);\n",
        "                  k=k+1;\n",
        "                }\n",
        "                k=0;\n",
        "                for(int i=1;i<rows1 * cols1* comp;i=i+3)\n",
        "                {\n",
        "                  G[k] =  static_cast<float>(data[i]);\n",
        "                  k=k+1;\n",
        "                }\n",
        "                k=0;\n",
        "                for(int i=2;i<rows1 * cols1* comp;i=i+3)\n",
        "                {\n",
        "                  B[k] =  static_cast<float>(data[i]);\n",
        "                  k=k+1;\n",
        "                }\n",
        "\n",
        "\n",
        "                memcpy(h_A, R, rows1*cols1 * sizeof(float));\n",
        "                memcpy(h_A +rows1*cols1 , G, rows1*cols1 * sizeof(float));\n",
        "                memcpy(h_A+rows1*cols1+rows1*cols1, B, rows1*cols1 * sizeof(float));\n",
        "\n",
        "                memcpy(h_images + img_index * rows1 * cols1 * 3,                     R, rows1 * cols1 * sizeof(float));\n",
        "                memcpy(h_images + img_index * rows1 * cols1 * 3 + rows1 * cols1,     G, rows1 * cols1 * sizeof(float));\n",
        "                memcpy(h_images + img_index * rows1 * cols1 * 3 + rows1 * cols1 * 2, B, rows1 * cols1 * sizeof(float));\n",
        "\n",
        "                img_index++;\n",
        "\n",
        "             }\n",
        "             else {\n",
        "                // Failed to load the image\n",
        "                std::cerr << \"Failed to load image: \" << filePath << std::endl;\n",
        "            }\n",
        "\n",
        "           }\n",
        "      }\n",
        "\n",
        "\n",
        "      float *d_images_temp = (float*)malloc(sizeof(float) * batch_size * rows1 * cols1 * comp);\n",
        "      for(int i=0; i<batch_size; i++){\n",
        "        memcpy(d_images_temp + i * rows1 * cols1 *comp , h_images + i * rows1 * cols1 *comp, rows1 * cols1 *comp * sizeof(float));\n",
        "      }\n",
        "\n",
        "\n",
        "    float *d_images;\n",
        "    cudaMalloc((void**)&d_images, batch_size * rows1 * cols1 * comp * sizeof(float));\n",
        "    cudaMemcpy(d_images, d_images_temp, batch_size * rows1 * cols1 * comp * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "    h_B =(float*)malloc(sizeof(float) * maskdim* maskdim*comp);\n",
        "\n",
        "    float *d_outs;\n",
        "    cudaMalloc((void**)&d_outs, batch_size * rows1 * cols1 * sizeof(float));\n",
        "\n",
        "    float *h_outs = (float*)malloc(sizeof(float) * batch_size * rows1 * cols1);\n",
        "\n",
        "\n",
        "    float *h_R, *h_G,*h_BB;\n",
        "    h_R =(float*)malloc(sizeof(float) * maskdim* maskdim);\n",
        "    h_G =(float*)malloc(sizeof(float) * maskdim* maskdim);\n",
        "    h_BB =(float*)malloc(sizeof(float) * maskdim* maskdim);\n",
        "    // Read mask elements\n",
        "    for (int i = 0; i < maskdim; ++i) {\n",
        "        for (int j = 0; j < maskdim; ++j) {\n",
        "\n",
        "            int index =  i * maskdim + j;\n",
        "            inputFile >>  h_R[index];\n",
        "            h_R[index]=h_R[index];\n",
        "            h_G[index]=h_R[index];\n",
        "            h_BB[index]=h_R[index];\n",
        "\n",
        "        }\n",
        "    }\n",
        "\n",
        "    memcpy(h_B, h_R,  maskdim* maskdim * sizeof(float));\n",
        "    memcpy(h_B + maskdim* maskdim , h_G, maskdim* maskdim * sizeof(float));\n",
        "    memcpy(h_B+maskdim* maskdim+maskdim* maskdim,  h_BB, maskdim* maskdim * sizeof(float));\n",
        "\n",
        "\n",
        "    // Copy data from host to device\n",
        "    //cudaMemcpyToSymbol(mask, h_B, maskdim * maskdim *comp * sizeof(float), 0, cudaMemcpyHostToDevice);\n",
        "\n",
        "    float * d_B ;\n",
        "    cudaMalloc((void**)&d_B, maskdim *  maskdim *comp * sizeof(float));\n",
        "    cudaMemcpy(d_B, h_B,   maskdim *  maskdim *comp * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Kernel invocation\n",
        "    dim3 threadsPerBlock(16, 16, 3);\n",
        "    dim3 numBlocks((cols1-1) / threadsPerBlock.x + 1, (rows1-1) / threadsPerBlock.y + 1, (batch_size-1) / threadsPerBlock.z + 1);\n",
        "    Imgcov3d<<<numBlocks, threadsPerBlock>>>(batch_size,d_images, d_outs,cols1,rows1,d_B, maskdim);\n",
        "\n",
        "    cudaMemcpy(h_outs, d_outs, batch_size * rows1 * cols1 * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    unsigned char* h_char = (unsigned char*)malloc(sizeof(unsigned char) * rows1 * cols1);\n",
        "\n",
        "    for(int k=0;k<batch_size;k++){\n",
        "\n",
        "      for(int i=0;i<rows1*cols1;i++){\n",
        "         h_char[i]=static_cast<unsigned char>(h_outs[k*rows1*cols1+i]);\n",
        "      }\n",
        "      string filename = \"./\"+out_path+\"/\"+\"image\" + std::to_string(k) + \".jpg\";\n",
        "      stbi_write_jpg(filename.c_str(), cols1, rows1, 1, h_char, 100);\n",
        "    }\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_images);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_outs);\n",
        "\n",
        "    // Free host memory\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(R);\n",
        "    free(G);\n",
        "    free(B);\n",
        "    free(h_images);\n",
        "    free(d_images_temp);\n",
        "    free(h_outs);\n",
        "    free(h_BB);\n",
        "    free(h_G);\n",
        "    free(h_R);\n",
        "    free(h_char);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x K1_2_31_2_33.cu\n",
        "!nvcc  K1_2_31_2_33.cu -o K1_2_31_2_33\n",
        "\n",
        "!./K1_2_31_2_33 \"in\" \"out1\" 4 \"mask.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wachg5FIL_3x",
        "outputId": "01c8dab7-d2b2-48ca-eab5-90e78f5d2378"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maskdim 11\n",
            "cols 255\n",
            "rows 255\n",
            "image in/you (1).jpg\n",
            "cols 255\n",
            "rows 255\n",
            "image in/cat (1).jpg\n",
            "cols 255\n",
            "rows 255\n",
            "image in/warda (1).jpg\n",
            "cols 255\n",
            "rows 255\n",
            "image in/camel.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./K1_2_31_2_33 \"in\" \"out1\" 4 \"mask.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YbA6xyBQK3y",
        "outputId": "eac2ed46-4b07-4e60-9f9c-eb90186534c6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maskdim 5\n",
            "cols 255\n",
            "rows 255\n",
            "image in/you (1).jpg\n",
            "cols 255\n",
            "rows 255\n",
            "image in/cat (1).jpg\n",
            "cols 255\n",
            "rows 255\n",
            "image in/warda (1).jpg\n",
            "cols 255\n",
            "rows 255\n",
            "image in/camel.jpg\n",
            "==4042== NVPROF is profiling process 4042, command: ./K1_2_31_2_33 in out1 4 mask.txt\n",
            "==4042== Profiling application: ./K1_2_31_2_33 in out1 4 mask.txt\n",
            "==4042== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   64.51%  524.95us         2  262.48us  1.0240us  523.93us  [CUDA memcpy HtoD]\n",
            "                   23.69%  192.80us         1  192.80us  192.80us  192.80us  Imgcov3d(int, float*, float*, unsigned int, unsigned int, float const *, int)\n",
            "                   11.80%  96.000us         1  96.000us  96.000us  96.000us  [CUDA memcpy DtoH]\n",
            "      API calls:   96.77%  73.099ms         3  24.366ms  7.0310us  72.977ms  cudaMalloc\n",
            "                    2.34%  1.7664ms         3  588.80us  12.033us  1.0621ms  cudaMemcpy\n",
            "                    0.43%  327.50us         3  109.17us  11.625us  174.80us  cudaFree\n",
            "                    0.25%  191.27us         1  191.27us  191.27us  191.27us  cudaLaunchKernel\n",
            "                    0.17%  128.85us       114  1.1300us     147ns  51.273us  cuDeviceGetAttribute\n",
            "                    0.01%  10.538us         1  10.538us  10.538us  10.538us  cuDeviceGetName\n",
            "                    0.01%  5.9980us         1  5.9980us  5.9980us  5.9980us  cuDeviceGetPCIBusId\n",
            "                    0.01%  4.6310us         1  4.6310us  4.6310us  4.6310us  cuDeviceTotalMem\n",
            "                    0.00%  2.5710us         2  1.2850us     176ns  2.3950us  cuDeviceGet\n",
            "                    0.00%  1.3420us         3     447ns     190ns     925ns  cuDeviceGetCount\n",
            "                    0.00%     441ns         1     441ns     441ns     441ns  cuModuleGetLoadingMode\n",
            "                    0.00%     208ns         1     208ns     208ns     208ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./K1_2_31_2_33 \"in1\" \"out1\" 1 \"mask.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzH9OGKtbGJx",
        "outputId": "c504342d-09af-4fc0-b355-ee697208d835"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maskdim 5\n",
            "cols 255\n",
            "rows 255\n",
            "image in1/cat (1).jpg\n",
            "==15197== NVPROF is profiling process 15197, command: ./K1_2_31_2_33 in1 out1 1 mask.txt\n",
            "==15197== Profiling application: ./K1_2_31_2_33 in1 out1 1 mask.txt\n",
            "==15197== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   42.31%  66.335us         2  33.167us     704ns  65.631us  [CUDA memcpy HtoD]\n",
            "                   39.27%  61.567us         1  61.567us  61.567us  61.567us  Imgcov3d(int, float*, float*, unsigned int, unsigned int, float const *, int)\n",
            "                   18.41%  28.864us         1  28.864us  28.864us  28.864us  [CUDA memcpy DtoH]\n",
            "      API calls:   98.65%  74.521ms         3  24.840ms  3.7410us  74.510ms  cudaMalloc\n",
            "                    0.69%  520.87us         3  173.62us  8.4200us  326.39us  cudaMemcpy\n",
            "                    0.26%  199.23us         1  199.23us  199.23us  199.23us  cudaLaunchKernel\n",
            "                    0.19%  147.03us         3  49.010us  5.7810us  121.01us  cudaFree\n",
            "                    0.17%  129.40us       114  1.1350us     140ns  52.293us  cuDeviceGetAttribute\n",
            "                    0.02%  11.823us         1  11.823us  11.823us  11.823us  cuDeviceGetName\n",
            "                    0.01%  5.7700us         1  5.7700us  5.7700us  5.7700us  cuDeviceGetPCIBusId\n",
            "                    0.01%  4.7990us         1  4.7990us  4.7990us  4.7990us  cuDeviceTotalMem\n",
            "                    0.00%  2.2270us         3     742ns     228ns  1.7050us  cuDeviceGetCount\n",
            "                    0.00%  1.1760us         2     588ns     180ns     996ns  cuDeviceGet\n",
            "                    0.00%     558ns         1     558ns     558ns     558ns  cuModuleGetLoadingMode\n",
            "                    0.00%     293ns         1     293ns     293ns     293ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmyNiiKDv1oi",
        "outputId": "652c6122-acea-4ca9-97e1-62b4a087bdf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting K2_2_31_2_33.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile K2_2_31_2_33.cu\n",
        "//Norhan_Reda_Abdelwahed_2_31\n",
        "//Hoda_Gamal_Hamouda_2_33\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <assert.h>\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <fstream>\n",
        "#include <vector>\n",
        "#define STB_IMAGE_IMPLEMENTATION\n",
        "#include <stdio.h>\n",
        "#include \"stb_image.h\"\n",
        "#define STB_IMAGE_WRITE_IMPLEMENTATION\n",
        "#include \"stb_image_write.h\"\n",
        "#include <string>\n",
        "#include <filesystem>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// Kernel definition\n",
        "__global__ void Imgcov3d(int batchSize, float *input, float* output, unsigned int width,unsigned int height, const float* __restrict__ mask,int maskdim, int shared_width,int shared_height, int shared_depth){\n",
        "\n",
        "  extern __shared__ float sharedTile [];\n",
        "\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "\n",
        "    int tile_x = shared_width - (maskdim - 1);\n",
        "    int tile_y = shared_height - (maskdim - 1);\n",
        "\n",
        "    int x_o = blockIdx.x * tile_x + threadIdx.x;\n",
        "    int y_o = blockIdx.y * tile_y + threadIdx.y;\n",
        "\n",
        "    int x_i = x_o - maskdim/2;\n",
        "    int y_i = y_o - maskdim/2;\n",
        "\n",
        "    int idx = blockIdx.z * blockDim.z + threadIdx.z;\n",
        "\n",
        "    if (idx >= batchSize){\n",
        "      return;\n",
        "    }\n",
        "\n",
        "  for (int d = 0; d < 3; d++) {\n",
        "\n",
        "    if (x_i >= 0 && y_i >= 0 && x_i < width && y_i < height){\n",
        "\n",
        "       sharedTile[idx * shared_width * shared_height * 3 + d * shared_height * shared_width + ty * shared_width + tx] =\n",
        "        input[idx * width * height * 3 + d * height * width + y_i * width + x_i];\n",
        "    }\n",
        "    else{\n",
        "       sharedTile[idx * shared_width * shared_height * 3 + d * shared_height * shared_width + ty * shared_width + tx] = 0;\n",
        "    }\n",
        "  }\n",
        "    __syncthreads();\n",
        "\n",
        "    float sum = 0.0;\n",
        "    if(ty < tile_y && tx < tile_x) {\n",
        "\n",
        "      for(int y_mask = 0; y_mask < maskdim; y_mask++) {\n",
        "            for(int x_mask = 0; x_mask < maskdim; x_mask++) {\n",
        "                  for(int z_mask = 0; z_mask < 3; z_mask++) {\n",
        "                    sum += mask[z_mask * maskdim * maskdim + y_mask * maskdim + x_mask] *\n",
        "                    sharedTile[idx * shared_height * shared_width * 3 + z_mask * shared_height * shared_width + (ty + y_mask) * shared_width +(tx + x_mask)];\n",
        "\n",
        "                }\n",
        "             }\n",
        "         }\n",
        "\n",
        "    if(sum < 0){\n",
        "      sum = 0;\n",
        "    } else if (sum > 255){\n",
        "      sum = 255;\n",
        "    }\n",
        "\n",
        "    if(y_o < height && x_o < width)\n",
        "        output[idx * width * height + y_o * width + x_o] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[]) {\n",
        "\n",
        "    string folderPath = argv[1];\n",
        "    string out_path = argv[2];\n",
        "    int batch_size = stoi(argv[3]);\n",
        "    string mask_path = argv[4];\n",
        "\n",
        "    int maskdim;\n",
        "\n",
        "    // Open the file for reading\n",
        "    std::ifstream inputFile(mask_path);\n",
        "\n",
        "    // Check if the file is opened successfully\n",
        "    if (!inputFile.is_open()) {\n",
        "        std::cerr << \"Error opening file: \" <<mask_path  << std::endl;\n",
        "        return 1; // Exit with an error code\n",
        "    }\n",
        "\n",
        "     inputFile >> maskdim ;\n",
        "     cout<<\"maskdim \"<<maskdim<<endl;\n",
        "\n",
        "    float *h_A, *h_B,*R,*G,*B;\n",
        "    int rows1,cols1, comp;\n",
        "\n",
        "    float *h_images;\n",
        "    int img_index = 0;\n",
        "\n",
        "    for (const auto& entry : std::filesystem::directory_iterator(folderPath)) {\n",
        "\n",
        "        if (entry.is_regular_file()) {\n",
        "            std::string filePath = entry.path().string();\n",
        "\n",
        "            unsigned char *data = stbi_load(filePath.c_str(), &cols1, &rows1, &comp, 0);\n",
        "\n",
        "            if(img_index == 0){\n",
        "              h_images = (float*)malloc(sizeof(float) * batch_size * cols1 * rows1 * comp);\n",
        "            }\n",
        "\n",
        "            if (data) {\n",
        "\n",
        "                printf(\"cols %d\\n\", cols1);\n",
        "                printf(\"rows %d\\n\", rows1);\n",
        "                printf(\"image %s\\n\", filePath.c_str());\n",
        "\n",
        "                h_A = (float*)malloc(sizeof(float) *  rows1 * cols1* comp);\n",
        "                R = (float*)malloc(sizeof(float) *  rows1 * cols1);\n",
        "                G = (float*)malloc(sizeof(float) *  rows1 * cols1);\n",
        "                B = (float*)malloc(sizeof(float) *  rows1 * cols1);\n",
        "\n",
        "                int k = 0;\n",
        "                for(int i=0;i<rows1 * cols1* comp;i=i+3)\n",
        "                {\n",
        "                  R[k] =  static_cast<float>(data[i]);\n",
        "                  k=k+1;\n",
        "                }\n",
        "                k=0;\n",
        "                for(int i=1;i<rows1 * cols1* comp;i=i+3)\n",
        "                {\n",
        "                  G[k] =  static_cast<float>(data[i]);\n",
        "                  k=k+1;\n",
        "                }\n",
        "                k=0;\n",
        "                for(int i=2;i<rows1 * cols1* comp;i=i+3)\n",
        "                {\n",
        "                  B[k] =  static_cast<float>(data[i]);\n",
        "                  k=k+1;\n",
        "                }\n",
        "\n",
        "\n",
        "                memcpy(h_A, R, rows1*cols1 * sizeof(float));\n",
        "                memcpy(h_A +rows1*cols1 , G, rows1*cols1 * sizeof(float));\n",
        "                memcpy(h_A+rows1*cols1+rows1*cols1, B, rows1*cols1 * sizeof(float));\n",
        "\n",
        "                memcpy(h_images + img_index * rows1 * cols1 * 3,                     R, rows1 * cols1 * sizeof(float));\n",
        "                memcpy(h_images + img_index * rows1 * cols1 * 3 + rows1 * cols1,     G, rows1 * cols1 * sizeof(float));\n",
        "                memcpy(h_images + img_index * rows1 * cols1 * 3 + rows1 * cols1 * 2, B, rows1 * cols1 * sizeof(float));\n",
        "\n",
        "                img_index++;\n",
        "\n",
        "             }\n",
        "             else {\n",
        "                // Failed to load the image\n",
        "                std::cerr << \"Failed to load image: \" << filePath << std::endl;\n",
        "            }\n",
        "\n",
        "           }\n",
        "      }\n",
        "\n",
        "\n",
        "      float *d_images_temp = (float*)malloc(sizeof(float) * batch_size * rows1 * cols1 * comp);\n",
        "      for(int i=0; i<batch_size; i++){\n",
        "        memcpy(d_images_temp + i * rows1 * cols1 *comp , h_images + i * rows1 * cols1 *comp, rows1 * cols1 *comp * sizeof(float));\n",
        "      }\n",
        "\n",
        "\n",
        "    float *d_images;\n",
        "    cudaMalloc((void**)&d_images, batch_size * rows1 * cols1 * comp * sizeof(float));\n",
        "    cudaMemcpy(d_images, d_images_temp, batch_size * rows1 * cols1 * comp * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    h_B =(float*)malloc(sizeof(float) * maskdim* maskdim*comp);\n",
        "\n",
        "    float *d_outs;\n",
        "    cudaMalloc((void**)&d_outs, batch_size * rows1 * cols1 * sizeof(float));\n",
        "\n",
        "    float *h_outs = (float*)malloc(sizeof(float) * batch_size * rows1 * cols1);\n",
        "\n",
        "    float *h_R, *h_G,*h_BB;\n",
        "    h_R =(float*)malloc(sizeof(float) * maskdim* maskdim);\n",
        "    h_G =(float*)malloc(sizeof(float) * maskdim* maskdim);\n",
        "    h_BB =(float*)malloc(sizeof(float) * maskdim* maskdim);\n",
        "    // Read mask elements\n",
        "    for (int i = 0; i < maskdim; ++i) {\n",
        "        for (int j = 0; j < maskdim; ++j) {\n",
        "\n",
        "            int index =  i * maskdim + j;\n",
        "            inputFile >>  h_R[index];\n",
        "            h_R[index]=h_R[index];\n",
        "            h_G[index]=h_R[index];\n",
        "            h_BB[index]=h_R[index];\n",
        "\n",
        "        }\n",
        "    }\n",
        "\n",
        "    memcpy(h_B, h_R,  maskdim* maskdim * sizeof(float));\n",
        "    memcpy(h_B + maskdim* maskdim , h_G, maskdim* maskdim * sizeof(float));\n",
        "    memcpy(h_B+maskdim* maskdim+maskdim* maskdim,  h_BB, maskdim* maskdim * sizeof(float));\n",
        "\n",
        "\n",
        "    // Copy data from host to device\n",
        "    //cudaMemcpyToSymbol(mask, h_B, maskdim * maskdim *comp * sizeof(float), 0, cudaMemcpyHostToDevice);\n",
        "\n",
        "    float * d_B ;\n",
        "    cudaMalloc((void**)&d_B, maskdim *  maskdim *comp * sizeof(float));\n",
        "    cudaMemcpy(d_B, h_B,   maskdim *  maskdim *comp * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Kernel invocation\n",
        "\n",
        "    dim3 threadsPerBlock(16, 16, 3);\n",
        "\n",
        "    int tile_x = threadsPerBlock.x - (maskdim - 1);\n",
        "    int tile_y = threadsPerBlock.y - (maskdim - 1);\n",
        "    //int tile_z = threadsPerBlock.z - (batch_size - 1);\n",
        "    int tile_z = threadsPerBlock.z;\n",
        "\n",
        "    int x_blocks = (cols1 + tile_x - 1) / tile_x;\n",
        "    int y_blocks = (rows1 + tile_y - 1) / tile_y;\n",
        "    int z_blocks = (batch_size + tile_z - 1) / tile_z;\n",
        "\n",
        "    int shared_width = tile_x + maskdim - 1;\n",
        "    int shared_height = tile_y + maskdim - 1;\n",
        "    //int shared_depth = tile_z + batch_size - 1;\n",
        "    int shared_depth = batch_size;\n",
        "\n",
        "    dim3 numBlocks(x_blocks, y_blocks, z_blocks);\n",
        "\n",
        "    Imgcov3d<<<numBlocks, threadsPerBlock,(sizeof(float)*shared_width*shared_height*3*shared_depth)>>>(batch_size,d_images,d_outs,cols1,rows1,d_B, maskdim,shared_width,shared_height,shared_depth);\n",
        "\n",
        "    cudaMemcpy(h_outs, d_outs, batch_size * rows1 * cols1 * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    unsigned char* h_char = (unsigned char*)malloc(sizeof(unsigned char) * rows1 * cols1);\n",
        "\n",
        "    for(int k=0;k<batch_size;k++){\n",
        "\n",
        "      for(int i=0;i<rows1*cols1;i++){\n",
        "         h_char[i]=static_cast<unsigned char>(h_outs[k*rows1*cols1+i]);\n",
        "      }\n",
        "      string filename = \"./\"+out_path+\"/\"+\"image\" + std::to_string(k) + \".jpg\";\n",
        "      stbi_write_jpg(filename.c_str(), cols1, rows1, 1, h_char, 100);\n",
        "    }\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_images);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_outs);\n",
        "\n",
        "    // Free host memory\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(R);\n",
        "    free(G);\n",
        "    free(B);\n",
        "    free(h_images);\n",
        "    free(d_images_temp);\n",
        "    free(h_outs);\n",
        "    free(h_BB);\n",
        "    free(h_G);\n",
        "    free(h_R);\n",
        "    free(h_char);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwqgGMOTv1k9",
        "outputId": "fb1f1428-c080-414c-939a-f6710e09dd53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maskdim 5\n",
            "cols 255\n",
            "rows 255\n",
            "image in/you (1).jpg\n",
            "cols 255\n",
            "rows 255\n",
            "image in/cat (1).jpg\n",
            "cols 255\n",
            "rows 255\n",
            "image in/warda (1).jpg\n",
            "cols 255\n",
            "rows 255\n",
            "image in/camel.jpg\n"
          ]
        }
      ],
      "source": [
        "!chmod +x K2_2_31_2_33.cu\n",
        "!nvcc  K2_2_31_2_33.cu -o K2_2_31_2_33\n",
        "\n",
        "!./K2_2_31_2_33 \"in\" \"out2\" 4 \"mask.txt\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./K2_2_31_2_33 \"in\" \"out2\" 4 \"mask.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKAlIbrzQHFl",
        "outputId": "a7e077fd-99ce-489b-a73f-4ab792d53235"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maskdim 5\n",
            "cols 255\n",
            "rows 255\n",
            "image in/you (1).jpg\n",
            "cols 255\n",
            "rows 255\n",
            "image in/cat (1).jpg\n",
            "cols 255\n",
            "rows 255\n",
            "image in/warda (1).jpg\n",
            "cols 255\n",
            "rows 255\n",
            "image in/camel.jpg\n",
            "==4130== NVPROF is profiling process 4130, command: ./K2_2_31_2_33 in out2 4 mask.txt\n",
            "==4130== Profiling application: ./K2_2_31_2_33 in out2 4 mask.txt\n",
            "==4130== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   59.85%  529.50us         2  264.75us  1.0240us  528.47us  [CUDA memcpy HtoD]\n",
            "                   27.16%  240.29us         1  240.29us  240.29us  240.29us  Imgcov3d(int, float*, float*, unsigned int, unsigned int, float const *, int, int, int, int)\n",
            "                   12.99%  114.91us         1  114.91us  114.91us  114.91us  [CUDA memcpy DtoH]\n",
            "      API calls:   96.49%  70.586ms         3  23.529ms  5.0290us  70.465ms  cudaMalloc\n",
            "                    2.55%  1.8641ms         3  621.36us  13.477us  1.1493ms  cudaMemcpy\n",
            "                    0.45%  329.44us         3  109.81us  8.3070us  195.47us  cudaFree\n",
            "                    0.30%  218.81us         1  218.81us  218.81us  218.81us  cudaLaunchKernel\n",
            "                    0.17%  127.78us       114  1.1200us     142ns  50.787us  cuDeviceGetAttribute\n",
            "                    0.02%  11.381us         1  11.381us  11.381us  11.381us  cuDeviceGetName\n",
            "                    0.01%  5.0080us         1  5.0080us  5.0080us  5.0080us  cuDeviceGetPCIBusId\n",
            "                    0.01%  4.3190us         1  4.3190us  4.3190us  4.3190us  cuDeviceTotalMem\n",
            "                    0.00%  1.4800us         3     493ns     198ns  1.0140us  cuDeviceGetCount\n",
            "                    0.00%     994ns         2     497ns     169ns     825ns  cuDeviceGet\n",
            "                    0.00%     625ns         1     625ns     625ns     625ns  cuModuleGetLoadingMode\n",
            "                    0.00%     296ns         1     296ns     296ns     296ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./K2_2_31_2_33 \"in1\" \"out2\" 1 \"mask.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37vamzgia6Vb",
        "outputId": "dd97376f-545a-48cb-f231-02d482b2c06d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maskdim 5\n",
            "cols 255\n",
            "rows 255\n",
            "image in1/cat (1).jpg\n",
            "==14922== NVPROF is profiling process 14922, command: ./K2_2_31_2_33 in1 out2 1 mask.txt\n",
            "==14922== Profiling application: ./K2_2_31_2_33 in1 out2 1 mask.txt\n",
            "==14922== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   48.49%  89.567us         1  89.567us  89.567us  89.567us  Imgcov3d(int, float*, float*, unsigned int, unsigned int, float const *, int, int, int, int)\n",
            "                   35.97%  66.432us         2  33.216us     704ns  65.728us  [CUDA memcpy HtoD]\n",
            "                   15.54%  28.704us         1  28.704us  28.704us  28.704us  [CUDA memcpy DtoH]\n",
            "      API calls:   98.65%  78.764ms         3  26.255ms  3.7240us  78.753ms  cudaMalloc\n",
            "                    0.69%  549.93us         3  183.31us  9.1090us  340.87us  cudaMemcpy\n",
            "                    0.29%  229.16us         1  229.16us  229.16us  229.16us  cudaLaunchKernel\n",
            "                    0.18%  146.37us         3  48.790us  6.0200us  118.10us  cudaFree\n",
            "                    0.16%  128.76us       114  1.1290us     129ns  51.246us  cuDeviceGetAttribute\n",
            "                    0.01%  11.464us         1  11.464us  11.464us  11.464us  cuDeviceGetName\n",
            "                    0.01%  5.9940us         1  5.9940us  5.9940us  5.9940us  cuDeviceGetPCIBusId\n",
            "                    0.01%  4.6410us         1  4.6410us  4.6410us  4.6410us  cuDeviceTotalMem\n",
            "                    0.00%  2.7680us         2  1.3840us     222ns  2.5460us  cuDeviceGet\n",
            "                    0.00%  1.6770us         3     559ns     205ns  1.1830us  cuDeviceGetCount\n",
            "                    0.00%     514ns         1     514ns     514ns     514ns  cuModuleGetLoadingMode\n",
            "                    0.00%     205ns         1     205ns     205ns     205ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bsmhvsQv1em",
        "outputId": "18802eb4-979f-4816-b708-fb31cb06fc08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting K3_2_31_2_33.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile K3_2_31_2_33.cu\n",
        "//Norhan_Reda_Abdelwahed_2_31\n",
        "//Hoda_Gamal_Hamouda_2_33\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <assert.h>\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <fstream>\n",
        "#include <vector>\n",
        "#define STB_IMAGE_IMPLEMENTATION\n",
        "#include <stdio.h>\n",
        "#include \"stb_image.h\"\n",
        "#define STB_IMAGE_WRITE_IMPLEMENTATION\n",
        "#include \"stb_image_write.h\"\n",
        "#include <string>\n",
        "#include <filesystem>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "\n",
        "__global__ void Imgcov3d(int batchSize, float *input, float* output, unsigned int width,unsigned int height, const float* __restrict__ mask,int maskdim, int shared_width,int shared_height, int shared_depth){\n",
        "\n",
        "  extern __shared__ float sharedTile [];\n",
        "\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "\n",
        "    int bx = blockIdx.x;\n",
        "    int by = blockIdx.y;\n",
        "\n",
        "    int tile_x = shared_width - (maskdim - 1);\n",
        "    int tile_y = shared_height - (maskdim - 1);\n",
        "\n",
        "    int x_o = blockIdx.x * tile_x + threadIdx.x;\n",
        "    int y_o = blockIdx.y * tile_y + threadIdx.y;\n",
        "\n",
        "    int idx = blockIdx.z * blockDim.z + threadIdx.z;\n",
        "\n",
        "    if (idx >= batchSize){\n",
        "      return;\n",
        "    }\n",
        "\n",
        "    int num = ((width*height) - 1) /(shared_width*shared_height) + 1;\n",
        "\n",
        "    for (int d=0; d< 3; d++){\n",
        "      for(int f=0; f < num ; f++){\n",
        "\n",
        "          int destTmp = tile_x * tile_y * f + ty * tile_x + tx;\n",
        "\n",
        "          int dX = destTmp % shared_width;\n",
        "          destTmp = destTmp / shared_width;\n",
        "          int dY = destTmp % shared_height;\n",
        "\n",
        "          int inputX = dX + (bx * tile_x) - (maskdim/2);\n",
        "          int inputY = dY + (by * tile_y) - (maskdim/2);\n",
        "\n",
        "          if(inputY >= 0 && inputY < height && inputX >= 0 && inputX < width){\n",
        "                sharedTile[idx * shared_width * shared_height * 3 + d * shared_height * shared_width + dY * shared_width + dX]\n",
        "                = input[idx * width * height * 3 + d * height * width + inputY * width + inputX];\n",
        "          }\n",
        "          else{\n",
        "              sharedTile[idx * shared_width * shared_height * 3 + d * shared_height * shared_width + dY * shared_width + dX] = 0.0;\n",
        "          }\n",
        "      }\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "  float sum = 0;\n",
        "\n",
        "    for(int y_mask = 0; y_mask < maskdim; y_mask++) {\n",
        "            for(int x_mask = 0; x_mask < maskdim; x_mask++) {\n",
        "                  for(int z_mask = 0; z_mask < 3; z_mask++) {\n",
        "                    sum += mask[z_mask * maskdim * maskdim + y_mask * maskdim + x_mask] *\n",
        "                    sharedTile[idx * shared_height * shared_width * 3 + z_mask * shared_height * shared_width + (ty + y_mask) * shared_width +(tx + x_mask)];\n",
        "\n",
        "                }\n",
        "             }\n",
        "         }\n",
        "\n",
        "    if(sum < 0){\n",
        "      sum = 0;\n",
        "    } else if (sum > 255){\n",
        "      sum = 255;\n",
        "    }\n",
        "\n",
        "    if(y_o < height && x_o < width){\n",
        "        output[idx * width * height + y_o * width + x_o] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[]) {\n",
        "\n",
        "    string folderPath = argv[1];\n",
        "    string out_path = argv[2];\n",
        "    int batch_size = stoi(argv[3]);\n",
        "    string mask_path = argv[4];\n",
        "\n",
        "    int maskdim;\n",
        "\n",
        "    // Open the file for reading\n",
        "    std::ifstream inputFile(mask_path);\n",
        "\n",
        "    // Check if the file is opened successfully\n",
        "    if (!inputFile.is_open()) {\n",
        "        std::cerr << \"Error opening file: \" <<mask_path  << std::endl;\n",
        "        return 1; // Exit with an error code\n",
        "    }\n",
        "\n",
        "     inputFile >> maskdim ;\n",
        "     cout<<\"maskdim \"<<maskdim<<endl;\n",
        "\n",
        "    float *h_A, *h_B,*R,*G,*B;\n",
        "    int rows1,cols1, comp;\n",
        "\n",
        "    float *h_images;\n",
        "    int img_index = 0;\n",
        "\n",
        "    for (const auto& entry : std::filesystem::directory_iterator(folderPath)) {\n",
        "\n",
        "        if (entry.is_regular_file()) {\n",
        "            std::string filePath = entry.path().string();\n",
        "\n",
        "            unsigned char *data = stbi_load(filePath.c_str(), &cols1, &rows1, &comp, 0);\n",
        "\n",
        "            if(img_index == 0){\n",
        "              h_images = (float*)malloc(sizeof(float) * batch_size * cols1 * rows1 * comp);\n",
        "            }\n",
        "\n",
        "            if (data) {\n",
        "\n",
        "                printf(\"cols %d\\n\", cols1);\n",
        "                printf(\"rows %d\\n\", rows1);\n",
        "                printf(\"image %s\\n\", filePath.c_str());\n",
        "\n",
        "                h_A = (float*)malloc(sizeof(float) *  rows1 * cols1* comp);\n",
        "                R = (float*)malloc(sizeof(float) *  rows1 * cols1);\n",
        "                G = (float*)malloc(sizeof(float) *  rows1 * cols1);\n",
        "                B = (float*)malloc(sizeof(float) *  rows1 * cols1);\n",
        "\n",
        "                int k = 0;\n",
        "                for(int i=0;i<rows1 * cols1* comp;i=i+3)\n",
        "                {\n",
        "                  R[k] =  static_cast<float>(data[i]);\n",
        "                  k=k+1;\n",
        "                }\n",
        "                k=0;\n",
        "                for(int i=1;i<rows1 * cols1* comp;i=i+3)\n",
        "                {\n",
        "                  G[k] =  static_cast<float>(data[i]);\n",
        "                  k=k+1;\n",
        "                }\n",
        "                k=0;\n",
        "                for(int i=2;i<rows1 * cols1* comp;i=i+3)\n",
        "                {\n",
        "                  B[k] =  static_cast<float>(data[i]);\n",
        "                  k=k+1;\n",
        "                }\n",
        "\n",
        "\n",
        "                memcpy(h_A, R, rows1*cols1 * sizeof(float));\n",
        "                memcpy(h_A +rows1*cols1 , G, rows1*cols1 * sizeof(float));\n",
        "                memcpy(h_A+rows1*cols1+rows1*cols1, B, rows1*cols1 * sizeof(float));\n",
        "\n",
        "                memcpy(h_images + img_index * rows1 * cols1 * 3,                     R, rows1 * cols1 * sizeof(float));\n",
        "                memcpy(h_images + img_index * rows1 * cols1 * 3 + rows1 * cols1,     G, rows1 * cols1 * sizeof(float));\n",
        "                memcpy(h_images + img_index * rows1 * cols1 * 3 + rows1 * cols1 * 2, B, rows1 * cols1 * sizeof(float));\n",
        "\n",
        "                img_index++;\n",
        "\n",
        "             }\n",
        "             else {\n",
        "                // Failed to load the image\n",
        "                std::cerr << \"Failed to load image: \" << filePath << std::endl;\n",
        "            }\n",
        "\n",
        "           }\n",
        "      }\n",
        "\n",
        "\n",
        "      float *d_images_temp = (float*)malloc(sizeof(float) * batch_size * rows1 * cols1 * comp);\n",
        "      for(int i=0; i<batch_size; i++){\n",
        "        memcpy(d_images_temp + i * rows1 * cols1 *comp , h_images + i * rows1 * cols1 *comp, rows1 * cols1 *comp * sizeof(float));\n",
        "      }\n",
        "\n",
        "\n",
        "    float *d_images;\n",
        "    cudaMalloc((void**)&d_images, batch_size * rows1 * cols1 * comp * sizeof(float));\n",
        "    cudaMemcpy(d_images, d_images_temp, batch_size * rows1 * cols1 * comp * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    h_B =(float*)malloc(sizeof(float) * maskdim* maskdim*comp);\n",
        "\n",
        "    float *d_outs;\n",
        "    cudaMalloc((void**)&d_outs, batch_size * rows1 * cols1 * sizeof(float));\n",
        "\n",
        "    float *h_outs = (float*)malloc(sizeof(float) * batch_size * rows1 * cols1);\n",
        "\n",
        "    float *h_R, *h_G,*h_BB;\n",
        "    h_R =(float*)malloc(sizeof(float) * maskdim* maskdim);\n",
        "    h_G =(float*)malloc(sizeof(float) * maskdim* maskdim);\n",
        "    h_BB =(float*)malloc(sizeof(float) * maskdim* maskdim);\n",
        "    // Read mask elements\n",
        "    for (int i = 0; i < maskdim; ++i) {\n",
        "        for (int j = 0; j < maskdim; ++j) {\n",
        "\n",
        "            int index =  i * maskdim + j;\n",
        "            inputFile >>  h_R[index];\n",
        "            h_R[index]=h_R[index];\n",
        "            h_G[index]=h_R[index];\n",
        "            h_BB[index]=h_R[index];\n",
        "\n",
        "        }\n",
        "    }\n",
        "\n",
        "    memcpy(h_B, h_R,  maskdim* maskdim * sizeof(float));\n",
        "    memcpy(h_B + maskdim* maskdim , h_G, maskdim* maskdim * sizeof(float));\n",
        "    memcpy(h_B+maskdim* maskdim+maskdim* maskdim,  h_BB, maskdim* maskdim * sizeof(float));\n",
        "\n",
        "\n",
        "    // Copy data from host to device\n",
        "    //cudaMemcpyToSymbol(mask, h_B, maskdim * maskdim *comp * sizeof(float), 0, cudaMemcpyHostToDevice);\n",
        "\n",
        "    float * d_B ;\n",
        "    cudaMalloc((void**)&d_B, maskdim *  maskdim *comp * sizeof(float));\n",
        "    cudaMemcpy(d_B, h_B,   maskdim *  maskdim *comp * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Kernel invocation\n",
        "\n",
        "    dim3 threadsPerBlock(16, 16, 3);\n",
        "\n",
        "    int tile_x = threadsPerBlock.x;\n",
        "    int tile_y = threadsPerBlock.y;\n",
        "    //int tile_z = threadsPerBlock.z;\n",
        "    int tile_z = threadsPerBlock.z;\n",
        "\n",
        "    int x_blocks = (cols1 + tile_x - 1) / tile_x;\n",
        "    int y_blocks = (rows1 + tile_y - 1) / tile_y;\n",
        "    int z_blocks = (batch_size + tile_z - 1) / tile_z;\n",
        "\n",
        "    int shared_width = tile_x + maskdim - 1;\n",
        "    int shared_height = tile_y + maskdim - 1;\n",
        "    //int shared_depth = tile_z + batch_size - 1;\n",
        "    int shared_depth = batch_size;\n",
        "\n",
        "    dim3 numBlocks(x_blocks, y_blocks, z_blocks);\n",
        "\n",
        "    Imgcov3d<<<numBlocks, threadsPerBlock,(sizeof(float)*shared_width*shared_height*3*shared_depth)>>>(batch_size,d_images,d_outs,cols1,rows1,d_B, maskdim,shared_width,shared_height,shared_depth);\n",
        "\n",
        "    cudaMemcpy(h_outs, d_outs, batch_size * rows1 * cols1 * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    unsigned char* h_char = (unsigned char*)malloc(sizeof(unsigned char) * rows1 * cols1);\n",
        "\n",
        "    for(int k=0;k<batch_size;k++){\n",
        "\n",
        "      for(int i=0;i<rows1*cols1;i++){\n",
        "         h_char[i]=static_cast<unsigned char>(h_outs[k*rows1*cols1+i]);\n",
        "      }\n",
        "      string filename = \"./\"+out_path+\"/\"+\"image\" + std::to_string(k) + \".jpg\";\n",
        "      stbi_write_jpg(filename.c_str(), cols1, rows1, 1, h_char, 100);\n",
        "    }\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_images);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_outs);\n",
        "\n",
        "    // Free host memory\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(R);\n",
        "    free(G);\n",
        "    free(B);\n",
        "    free(h_images);\n",
        "    free(d_images_temp);\n",
        "    free(h_outs);\n",
        "    free(h_BB);\n",
        "    free(h_G);\n",
        "    free(h_R);\n",
        "    free(h_char);\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY2F3ITlv1T7",
        "outputId": "33a5c31f-cbd2-4954-a0be-c2044cd7f171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maskdim 5\n",
            "cols 255\n",
            "rows 255\n",
            "image in/you (1).jpg\n",
            "cols 255\n",
            "rows 255\n",
            "image in/cat (1).jpg\n",
            "cols 255\n",
            "rows 255\n",
            "image in/warda (1).jpg\n",
            "cols 255\n",
            "rows 255\n",
            "image in/camel.jpg\n"
          ]
        }
      ],
      "source": [
        "!chmod +x K3_2_31_2_33.cu\n",
        "!nvcc  K3_2_31_2_33.cu -o K3_2_31_2_33\n",
        "\n",
        "!./K3_2_31_2_33 \"in\" \"out3\" 4 \"mask.txt\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./K3_2_31_2_33 \"in\" \"out3\" 4 \"mask.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ylj-P2QhPMsE",
        "outputId": "7ab640c0-3d4b-4b69-df0b-c74bbeabc827"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maskdim 5\n",
            "cols 255\n",
            "rows 255\n",
            "image in/you (1).jpg\n",
            "cols 255\n",
            "rows 255\n",
            "image in/cat (1).jpg\n",
            "cols 255\n",
            "rows 255\n",
            "image in/warda (1).jpg\n",
            "cols 255\n",
            "rows 255\n",
            "image in/camel.jpg\n",
            "==5975== NVPROF is profiling process 5975, command: ./K3_2_31_2_33 in out3 4 mask.txt\n",
            "==5975== Profiling application: ./K3_2_31_2_33 in out3 4 mask.txt\n",
            "==5975== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   84.59%  3.4652ms         1  3.4652ms  3.4652ms  3.4652ms  Imgcov3d(int, float*, float*, unsigned int, unsigned int, float const *, int, int, int, int)\n",
            "                   13.10%  536.83us         2  268.41us  1.0240us  535.80us  [CUDA memcpy HtoD]\n",
            "                    2.30%  94.399us         1  94.399us  94.399us  94.399us  [CUDA memcpy DtoH]\n",
            "      API calls:   92.25%  70.126ms         3  23.375ms  7.3160us  69.999ms  cudaMalloc\n",
            "                    6.68%  5.0745ms         3  1.6915ms  13.450us  4.3413ms  cudaMemcpy\n",
            "                    0.48%  362.03us         3  120.68us  9.9060us  195.11us  cudaFree\n",
            "                    0.39%  297.01us         1  297.01us  297.01us  297.01us  cudaLaunchKernel\n",
            "                    0.17%  130.67us       114  1.1460us     142ns  52.025us  cuDeviceGetAttribute\n",
            "                    0.02%  15.981us         1  15.981us  15.981us  15.981us  cuDeviceGetName\n",
            "                    0.01%  5.3310us         1  5.3310us  5.3310us  5.3310us  cuDeviceGetPCIBusId\n",
            "                    0.01%  4.8980us         1  4.8980us  4.8980us  4.8980us  cuDeviceTotalMem\n",
            "                    0.00%  1.3950us         3     465ns     172ns     909ns  cuDeviceGetCount\n",
            "                    0.00%  1.3260us         2     663ns     331ns     995ns  cuDeviceGet\n",
            "                    0.00%     555ns         1     555ns     555ns     555ns  cuModuleGetLoadingMode\n",
            "                    0.00%     231ns         1     231ns     231ns     231ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./K3_2_31_2_33 \"in1\" \"out3\" 1 \"mask.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L5RwBuGZzg8",
        "outputId": "b7abd812-6529-486e-da3d-03cb1b6a66e2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maskdim 5\n",
            "cols 255\n",
            "rows 255\n",
            "image in1/cat (1).jpg\n",
            "==14379== NVPROF is profiling process 14379, command: ./K3_2_31_2_33 in1 out3 1 mask.txt\n",
            "==14379== Profiling application: ./K3_2_31_2_33 in1 out3 1 mask.txt\n",
            "==14379== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   91.01%  955.06us         1  955.06us  955.06us  955.06us  Imgcov3d(int, float*, float*, unsigned int, unsigned int, float const *, int, int, int, int)\n",
            "                    6.36%  66.752us         2  33.376us     704ns  66.048us  [CUDA memcpy HtoD]\n",
            "                    2.63%  27.616us         1  27.616us  27.616us  27.616us  [CUDA memcpy DtoH]\n",
            "      API calls:   97.48%  74.543ms         3  24.848ms  8.8370us  74.523ms  cudaMalloc\n",
            "                    1.80%  1.3775ms         3  459.16us  11.529us  1.1832ms  cudaMemcpy\n",
            "                    0.33%  251.32us         1  251.32us  251.32us  251.32us  cudaLaunchKernel\n",
            "                    0.18%  135.93us         3  45.309us  5.7360us  111.18us  cudaFree\n",
            "                    0.18%  134.90us       114  1.1830us     137ns  50.652us  cuDeviceGetAttribute\n",
            "                    0.02%  12.264us         1  12.264us  12.264us  12.264us  cuDeviceGetName\n",
            "                    0.01%  6.0310us         1  6.0310us  6.0310us  6.0310us  cuDeviceTotalMem\n",
            "                    0.01%  5.1930us         1  5.1930us  5.1930us  5.1930us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.0100us         3     670ns     203ns  1.3530us  cuDeviceGetCount\n",
            "                    0.00%  1.4030us         2     701ns     340ns  1.0630us  cuDeviceGet\n",
            "                    0.00%     612ns         1     612ns     612ns     612ns  cuModuleGetLoadingMode\n",
            "                    0.00%     418ns         1     418ns     418ns     418ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF97Xzl2ucIa",
        "outputId": "2cccf91e-7d1e-41d2-ce7b-40086bf165ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maskdim 5\n",
            "[[[0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]]\n",
            "\n",
            " [[0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]]\n",
            "\n",
            " [[0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]]]\n",
            "MASKDIM: 5\n",
            "Matrix:\n",
            "[[[0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]]\n",
            "\n",
            " [[0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]]\n",
            "\n",
            " [[0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]]]\n",
            "tensor([[[0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130]],\n",
            "\n",
            "        [[0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130]],\n",
            "\n",
            "        [[0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130]]], dtype=torch.float64)\n",
            "(255, 255, 3)\n",
            "===> 255 32394\n",
            "2\n",
            "(259, 259, 3)\n",
            "Data type of input_image: uint8\n",
            "torch.Size([3, 259, 259])\n",
            "Data type of input_image: torch.float32\n",
            "torch.Size([1, 3, 259, 259])\n",
            "[[[27 37 46 ... 27 21 15]\n",
            "  [37 49 62 ... 36 28 21]\n",
            "  [46 62 78 ... 45 36 26]\n",
            "  ...\n",
            "  [58 78 99 ... 57 44 32]\n",
            "  [45 61 77 ... 43 33 24]\n",
            "  [33 45 57 ... 29 22 16]]]\n",
            "[[[27 37 46 ... 27 21 15]\n",
            "  [37 49 62 ... 36 28 21]\n",
            "  [46 62 78 ... 45 36 26]\n",
            "  ...\n",
            "  [58 78 99 ... 57 44 32]\n",
            "  [45 61 77 ... 43 33 24]\n",
            "  [33 45 57 ... 29 22 16]]]\n",
            "Execution time: 0.004110097885131836 seconds\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Define the mask tensor\n",
        "file_path = \"mask.txt\"\n",
        "\n",
        "# Open the file in read mode\n",
        "with open(file_path, \"r\") as file:\n",
        "    # Read the lines of the file\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Remove any leading or trailing whitespace characters from each line\n",
        "lines = [line.strip() for line in lines]\n",
        "\n",
        "# Extract the first line and assign it to a variable\n",
        "MASKDIM= int(lines[0])\n",
        "print(\"maskdim\",MASKDIM)\n",
        "# Extract the remaining lines and create a matrix\n",
        "mask = [(line.split()) for line in lines[1:]]\n",
        "# Convert the list to a numpy array\n",
        "array_2d = np.array(mask, dtype=float)\n",
        "\n",
        "# Convert the 2D array to a 3D array\n",
        "mask = np.repeat(array_2d[np.newaxis, ...], 3, axis=0)\n",
        "\n",
        "print(mask)\n",
        "\n",
        "# Process the variables\n",
        "print(\"MASKDIM:\",MASKDIM )\n",
        "print(\"Matrix:\")\n",
        "# for row in mask:\n",
        "#     print(row)\n",
        "print(mask)\n",
        "mask = torch.from_numpy(mask)\n",
        "print(mask)\n",
        "\n",
        "mask = mask.unsqueeze(0).unsqueeze(0)\n",
        "mask= mask.float()\n",
        "\n",
        "# Read the RGB image using OpenCV\n",
        "# image = cv2.imread('you.jpg')\n",
        "# image = cv2.imread('camel.png')\n",
        "image = cv2.imread('cat.jpg')\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "print(image.shape)\n",
        "#print(image[0])\n",
        "image_array = np.array(image)\n",
        "max_value = np.max(image_array)\n",
        "max_value_arg = np.argmax(image_array)\n",
        "print('===>', max_value, max_value_arg)\n",
        "\n",
        "# Define the padding size\n",
        "padding = (MASKDIM - 1) // 2\n",
        "print(padding)\n",
        "\n",
        "pad_height = (padding, padding)  # Pad 2 pixels on each side along height\n",
        "pad_width = (padding, padding)  # Pad 2 pixels on each side along width\n",
        "pad_channels = (0, 0)  # No padding along channels (RGB)\n",
        "\n",
        "# Pad the image\n",
        "padded_image = np.pad(image, (pad_height, pad_width, pad_channels), mode='constant', constant_values=0)  # Pad with zeros\n",
        "print(padded_image.shape)\n",
        "print(\"Data type of input_image:\", padded_image.dtype)\n",
        "\n",
        "# Convert the image to a PyTorch tensor\n",
        "transform = transforms.ToTensor()\n",
        "input_image = transform(padded_image)\n",
        "print(input_image.shape)\n",
        "print(\"Data type of input_image:\", input_image.dtype)\n",
        "\n",
        "input_image = input_image * 255\n",
        "\n",
        "# Expand the dimensions of the input image to make it 3D\n",
        "input_image = input_image.unsqueeze(0)\n",
        "print(input_image.shape)\n",
        "\n",
        "# Pad the input image\n",
        "# padded_image = F.pad(input_image, (padding, padding, padding, padding, padding, padding))\n",
        "\n",
        "\n",
        "# Perform the 3D convolution using PyTorch\n",
        "# Start the timer\n",
        "start_time = time.time()\n",
        "output_tensor = F.conv3d(input_image, mask)\n",
        "# Stop the timer\n",
        "end_time = time.time()\n",
        "output_tensor = output_tensor.to(torch.int)\n",
        "\n",
        "# Remove the batch dimension and convert the output tensor to numpy array\n",
        "output_array = output_tensor.squeeze(0).numpy()\n",
        "# output_array=output_array*255\n",
        "# Print the output array\n",
        "print(output_array)\n",
        "\n",
        "output_array = np.clip(output_array, 0, 255)  # Clip values to the range [0, 255]\n",
        "print(output_array)\n",
        "cv2.imwrite('pyimg_cpu.jpg', output_array.reshape(image.shape[0],image.shape[1],1))\n",
        "# Calculate the execution time\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "# Print the execution time\n",
        "print(\"Execution time:\", execution_time, \"seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Define the mask tensor\n",
        "file_path = \"mask.txt\"\n",
        "\n",
        "# Open the file in read mode\n",
        "with open(file_path, \"r\") as file:\n",
        "    # Read the lines of the file\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Remove any leading or trailing whitespace characters from each line\n",
        "lines = [line.strip() for line in lines]\n",
        "\n",
        "# Extract the first line and assign it to a variable\n",
        "MASKDIM = int(lines[0])\n",
        "print(\"maskdim\", MASKDIM)\n",
        "# Extract the remaining lines and create a matrix\n",
        "mask = [(line.split()) for line in lines[1:]]\n",
        "# Convert the list to a numpy array\n",
        "array_2d = np.array(mask, dtype=float)\n",
        "\n",
        "# Convert the 2D array to a 3D array\n",
        "mask = np.repeat(array_2d[np.newaxis, ...], 3, axis=0)\n",
        "\n",
        "print(mask)\n",
        "\n",
        "# Process the variables\n",
        "print(\"MASKDIM:\", MASKDIM)\n",
        "print(\"Matrix:\")\n",
        "# for row in mask:\n",
        "#     print(row)\n",
        "print(mask)\n",
        "\n",
        "# Convert the mask to a PyTorch tensor\n",
        "mask = torch.from_numpy(mask).cuda()\n",
        "print(mask)\n",
        "\n",
        "mask = mask.unsqueeze(0).unsqueeze(0)\n",
        "mask = mask.float()\n",
        "\n",
        "# Read the RGB image using OpenCV\n",
        "# image = cv2.imread('you.jpg')\n",
        "# image = cv2.imread('camel.png')\n",
        "image = cv2.imread('cat.jpg')\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "print(image.shape)\n",
        "# print(image[0])\n",
        "image_array = np.array(image)\n",
        "max_value = np.max(image_array)\n",
        "max_value_arg = np.argmax(image_array)\n",
        "print('===>', max_value, max_value_arg)\n",
        "\n",
        "# Define the padding size\n",
        "padding = (MASKDIM - 1) // 2\n",
        "print(padding)\n",
        "\n",
        "pad_height = (padding, padding)  # Pad 2 pixels on each side along height\n",
        "pad_width = (padding, padding)  # Pad 2 pixels on each side along width\n",
        "pad_channels = (0, 0)  # No padding along channels (RGB)\n",
        "\n",
        "# Pad the image\n",
        "padded_image = np.pad(image, (pad_height, pad_width, pad_channels), mode='constant', constant_values=0)  # Pad with zeros\n",
        "print(padded_image.shape)\n",
        "print(\"Data type of input_image:\", padded_image.dtype)\n",
        "\n",
        "# Convert the image to a PyTorch tensor\n",
        "transform = transforms.ToTensor()\n",
        "input_image = transform(padded_image)\n",
        "print(input_image.shape)\n",
        "print(\"Data type of input_image:\", input_image.dtype)\n",
        "\n",
        "input_image = input_image * 255\n",
        "\n",
        "# Expand the dimensions of the input image to make it 3D\n",
        "input_image = input_image.unsqueeze(0).cuda()\n",
        "print(input_image.shape)\n",
        "\n",
        "# Perform the 3D convolution using PyTorch\n",
        "# Start the timer\n",
        "start_time = time.time()\n",
        "output_tensor = F.conv3d(input_image, mask)\n",
        "# Stop the timer\n",
        "end_time = time.time()\n",
        "output_tensor = output_tensor.to(torch.int)\n",
        "\n",
        "# Remove the batch dimension and convert the output tensor to a numpy array\n",
        "output_array = output_tensor.squeeze(0).cpu().numpy()\n",
        "# output_array=output_array*255\n",
        "# Print the output array\n",
        "print(output_array)\n",
        "\n",
        "output_array = np.clip(output_array, 0, 255)  # Clip values to the range [0, 255]\n",
        "print(output_array)\n",
        "cv2.imwrite('pyimg_gpu.jpg', output_array.reshape(image.shape[0], image.shape[1], 1))\n",
        "# Calculate the execution time\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "# Print the execution time\n",
        "print(\"Execution time:\", execution_time, \"seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFa2WQ0dW2uR",
        "outputId": "a682db4a-df0b-44c4-eeae-f4036853e3e9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maskdim 5\n",
            "[[[0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]]\n",
            "\n",
            " [[0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]]\n",
            "\n",
            " [[0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]]]\n",
            "MASKDIM: 5\n",
            "Matrix:\n",
            "[[[0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]]\n",
            "\n",
            " [[0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]]\n",
            "\n",
            " [[0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]]]\n",
            "tensor([[[0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130]],\n",
            "\n",
            "        [[0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130]],\n",
            "\n",
            "        [[0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130]]], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "(255, 255, 3)\n",
            "===> 255 32394\n",
            "2\n",
            "(259, 259, 3)\n",
            "Data type of input_image: uint8\n",
            "torch.Size([3, 259, 259])\n",
            "Data type of input_image: torch.float32\n",
            "torch.Size([1, 3, 259, 259])\n",
            "[[[27 37 46 ... 27 21 15]\n",
            "  [37 49 62 ... 36 28 21]\n",
            "  [46 62 78 ... 45 36 26]\n",
            "  ...\n",
            "  [58 78 99 ... 57 44 32]\n",
            "  [45 61 77 ... 43 33 24]\n",
            "  [33 45 57 ... 29 22 16]]]\n",
            "[[[27 37 46 ... 27 21 15]\n",
            "  [37 49 62 ... 36 28 21]\n",
            "  [46 62 78 ... 45 36 26]\n",
            "  ...\n",
            "  [58 78 99 ... 57 44 32]\n",
            "  [45 61 77 ... 43 33 24]\n",
            "  [33 45 57 ... 29 22 16]]]\n",
            "Execution time: 0.0005440711975097656 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDBKHRShYAUt",
        "outputId": "2ad67f35-5120-498c-cf8d-e234bf0dca72"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "# Define the mask tensor\n",
        "file_path = \"mask.txt\"\n",
        "\n",
        "# Open the file in read mode\n",
        "with open(file_path, \"r\") as file:\n",
        "    # Read the lines of the file\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Remove any leading or trailing whitespace characters from each line\n",
        "lines = [line.strip() for line in lines]\n",
        "\n",
        "# Extract the first line and assign it to a variable\n",
        "MASKDIM = int(lines[0])\n",
        "print(\"maskdim\", MASKDIM)\n",
        "# Extract the remaining lines and create a matrix\n",
        "mask = [(line.split()) for line in lines[1:]]\n",
        "# Convert the list to a numpy array\n",
        "array_2d = np.array(mask, dtype=float)\n",
        "\n",
        "# Convert the 2D array to a 3D array\n",
        "mask = np.repeat(array_2d[np.newaxis, ...], 3, axis=0)\n",
        "\n",
        "print(mask)\n",
        "\n",
        "# Process the variables\n",
        "print(\"MASKDIM:\", MASKDIM)\n",
        "print(\"Matrix:\")\n",
        "# for row in mask:\n",
        "#     print(row)\n",
        "print(mask)\n",
        "\n",
        "# Convert the mask to a PyTorch tensor\n",
        "mask = torch.from_numpy(mask)\n",
        "\n",
        "print(mask)\n",
        "\n",
        "mask = mask.unsqueeze(0).unsqueeze(0)\n",
        "mask = mask.float()\n",
        "\n",
        "# Read the RGB image using OpenCV\n",
        "# image = cv2.imread('you.jpg')\n",
        "# image = cv2.imread('camel.png')\n",
        "image = cv2.imread('cat.jpg')\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "print(image.shape)\n",
        "# print(image[0])\n",
        "image_array = np.array(image)\n",
        "max_value = np.max(image_array)\n",
        "max_value_arg = np.argmax(image_array)\n",
        "print('===>', max_value, max_value_arg)\n",
        "\n",
        "# Define the padding size\n",
        "padding = (MASKDIM - 1) // 2\n",
        "print(padding)\n",
        "\n",
        "pad_height = (padding, padding)  # Pad 2 pixels on each side along height\n",
        "pad_width = (padding, padding)  # Pad 2 pixels on each side along width\n",
        "pad_channels = (0, 0)  # No padding along channels (RGB)\n",
        "\n",
        "# Pad the image\n",
        "padded_image = np.pad(image, (pad_height, pad_width, pad_channels), mode='constant', constant_values=0)  # Pad with zeros\n",
        "print(padded_image.shape)\n",
        "print(\"Data type of input_image:\", padded_image.dtype)\n",
        "\n",
        "# Convert the image to a PyTorch tensor\n",
        "transform = transforms.ToTensor()\n",
        "input_image = transform(padded_image)\n",
        "print(input_image.shape)\n",
        "print(\"Data type of input_image:\", input_image.dtype)\n",
        "\n",
        "input_image = input_image * 255\n",
        "\n",
        "# Expand the dimensions of the input image to make it 3D\n",
        "input_image = input_image.unsqueeze(0)\n",
        "print(input_image.shape)\n",
        "\n",
        "mask = mask.to(device)\n",
        "input_image = input_image.to(device)\n",
        "\n",
        "# Perform the 3D convolution using PyTorch\n",
        "# Start the timer\n",
        "start_time = time.time()\n",
        "output_tensor = F.conv3d(input_image, mask)\n",
        "# Stop the timer\n",
        "end_time = time.time()\n",
        "output_tensor = output_tensor.to(torch.int)\n",
        "\n",
        "# Remove the batch dimension and convert the output tensor to a numpy array\n",
        "output_array = output_tensor.squeeze(0).cpu().numpy()\n",
        "# output_array=output_array*255\n",
        "# Print the output array\n",
        "print(output_array)\n",
        "\n",
        "output_array = np.clip(output_array, 0, 255)  # Clip values to the range [0, 255]\n",
        "print(output_array)\n",
        "cv2.imwrite('pyimg_gpu.jpg', output_array.reshape(image.shape[0], image.shape[1], 1))\n",
        "# Calculate the execution time\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "# Print the execution time\n",
        "print(\"Execution time:\", execution_time, \"seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPl8A9iZYEJB",
        "outputId": "2ddbcff9-323c-4b80-fed4-36013281f097"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "maskdim 5\n",
            "[[[0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]]\n",
            "\n",
            " [[0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]]\n",
            "\n",
            " [[0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]]]\n",
            "MASKDIM: 5\n",
            "Matrix:\n",
            "[[[0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]]\n",
            "\n",
            " [[0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]]\n",
            "\n",
            " [[0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]\n",
            "  [0.013 0.013 0.013 0.013 0.013]]]\n",
            "tensor([[[0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130]],\n",
            "\n",
            "        [[0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130]],\n",
            "\n",
            "        [[0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130],\n",
            "         [0.0130, 0.0130, 0.0130, 0.0130, 0.0130]]], dtype=torch.float64)\n",
            "(255, 255, 3)\n",
            "===> 255 32394\n",
            "2\n",
            "(259, 259, 3)\n",
            "Data type of input_image: uint8\n",
            "torch.Size([3, 259, 259])\n",
            "Data type of input_image: torch.float32\n",
            "torch.Size([1, 3, 259, 259])\n",
            "[[[27 37 46 ... 27 21 15]\n",
            "  [37 49 62 ... 36 28 21]\n",
            "  [46 62 78 ... 45 36 26]\n",
            "  ...\n",
            "  [58 78 99 ... 57 44 32]\n",
            "  [45 61 77 ... 43 33 24]\n",
            "  [33 45 57 ... 29 22 16]]]\n",
            "[[[27 37 46 ... 27 21 15]\n",
            "  [37 49 62 ... 36 28 21]\n",
            "  [46 62 78 ... 45 36 26]\n",
            "  ...\n",
            "  [58 78 99 ... 57 44 32]\n",
            "  [45 61 77 ... 43 33 24]\n",
            "  [33 45 57 ... 29 22 16]]]\n",
            "Execution time: 0.0002338886260986328 seconds\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}